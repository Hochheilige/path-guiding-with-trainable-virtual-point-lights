{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import drjit as dr\n",
    "import mitsuba as mi\n",
    "\n",
    "mi.set_variant(\"cuda_ad_rgb\")\n",
    "\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from mitsuba.python.ad.integrators.common import ADIntegrator, mis_weight\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "import tinycudann as tcnn \n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default cornell box\n",
    "scene_dict = mi.cornell_box()\n",
    "scene_dict['sphere'] = {\n",
    "    'type': 'sphere',\n",
    "    'radius': 0.4,\n",
    "    'center': [0, 0.2, 0], \n",
    "    'bsdf': {\n",
    "        'type': 'roughconductor',\n",
    "        'alpha': 0.3  \n",
    "    }\n",
    "}\n",
    "scene = mi.load_dict(scene_dict)\n",
    "\n",
    "original_image = mi.render(scene, spp=16)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.patch.set_visible(False)  # Hide the figure's background\n",
    "ax.axis('off')  # Remove the axes from the image\n",
    "fig.tight_layout()  # Remove any extra white spaces around the image\n",
    "ax.imshow(np.clip(original_image ** (1.0 / 2.2), 0, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In relation to Hierachical Light Sampling paper by AMD, light is going to be represented as pair of Gaussian + vMF\n",
    "    * Isotropic Gaussian, approximates the light positions distirbution\n",
    "        μ - mean (centre of Gaussian)\n",
    "        σ2 - variance (spread of distribution)\n",
    "    * vMF, approximates directional distirbution of radiant intensity (Normalized Gaussian)\n",
    "        κ - sharpness\n",
    "        ν - axis\n",
    "        α - amplitude\n",
    "\n",
    "So final struct that we have:\n",
    "[\n",
    "    vec3  mean\n",
    "    float variance\n",
    "    float sharpness\n",
    "    vec3  axis\n",
    "    vec3  amplitude\n",
    "]\n",
    "\n",
    "Going to call Gaussian vMF pair - Virtual Anisotropic Point Light - VAPL\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class vapl_grid(torch.nn.Module):\n",
    "    def __init__(self, bb_min, bb_max, num_gaussian_in_mixture, num_param_per_gaussian, num_param_per_vmf):\n",
    "        super().__init__()\n",
    "\n",
    "        self.bb_min = bb_min\n",
    "        self.bb_max = bb_max\n",
    "\n",
    "        # tiny-cuda-nn config for hash grid\n",
    "        config = {\n",
    "            \"encoding\": {\n",
    "                \"otype\": \"HashGrid\",\n",
    "                \"base_resolution\": 16,\n",
    "                \"n_levels\": num_gaussian_in_mixture,\n",
    "                \"n_features_per_level\": num_param_per_gaussian,\n",
    "                \"log2_hashmap_size\": 22,\n",
    "            },\n",
    "        }\n",
    "        n_input_dims = 3\n",
    "        self.gaussian_grid = tcnn.Encoding(n_input_dims, config[\"encoding\"])\n",
    "\n",
    "        config[\"encoding\"][\"n_features_per_level\"] = num_param_per_vmf\n",
    "        self.vmf_grid = tcnn.Encoding(n_input_dims, config[\"encoding\"])\n",
    "\n",
    "        self.sg_optimizer = torch.optim.Adam(self.gaussian_grid.parameters(), lr=0.01)\n",
    "        self.vmf_optimizer = torch.optim.Adam(self.vmf_grid.parameters(), lr = 0.01)\n",
    "\n",
    "    def forward(self, si):\n",
    "        with dr.suspend_grad():\n",
    "            # get the position of ray-scene intersection in scene bb\n",
    "            X = ((si.p - self.bb_min) / (self.bb_max - self.bb_min)).torch()\n",
    "            gaussians : torch.Tensor = self.gaussian_grid(X.T)\n",
    "            gaussians.requires_grad_()\n",
    "            vmf : torch.Tensor = self.vmf_grid(X.T)\n",
    "            vmf.requires_grad_()\n",
    "\n",
    "        eps = 1e-2\n",
    "        \n",
    "        mean = gaussians[:, :3]\n",
    "        bb_min = torch.tensor(self.bb_min, device=mean.device)\n",
    "        bb_max = torch.tensor(self.bb_max, device=mean.device)\n",
    "        \n",
    "        mean = mean / eps * 0.5 + 0.5\n",
    "        mean = mean * (bb_max - bb_min).unsqueeze(0) + bb_min.unsqueeze(0)\n",
    "        \n",
    "        variance = gaussians[:, 3]\n",
    "        variance = torch.relu(variance)\n",
    "\n",
    "        sharpness = vmf[:, 0]\n",
    "        sharpness = torch.exp(sharpness)\n",
    "\n",
    "        axis = vmf[:, 1:4]\n",
    "        norm = torch.norm(axis, dim=1, keepdim=True)  \n",
    "        axis = torch.div(axis, norm + 1e-6)\n",
    "\n",
    "        amplitude = vmf[:, 4:7]\n",
    "        amplitude = torch.relu(vmf[:, 4:7])\n",
    "\n",
    "        variance = variance.unsqueeze(1)\n",
    "        sharpness = sharpness.unsqueeze(1)\n",
    "    \n",
    "        gaussians = torch.cat([mean, variance], dim = 1)\n",
    "        vmf = torch.cat([sharpness, axis, amplitude], dim = 1)\n",
    "\n",
    "        return gaussians, vmf    \n",
    "\n",
    "def get_camera_first_bounce(scene):\n",
    "    cam_origin = mi.Point3f(0, 1, 3)\n",
    "    cam_dir = dr.normalize(mi.Vector3f(0, -0.5, -1))\n",
    "    cam_width = 2.0\n",
    "    cam_height = 2.0\n",
    "    image_res = [4, 4]\n",
    "\n",
    "    x, y = dr.meshgrid(\n",
    "        dr.linspace(mi.Float, -cam_width / 2, cam_width / 2, image_res[0]),\n",
    "        dr.linspace(mi.Float, -cam_height / 2, cam_height / 2, image_res[1]),\n",
    "    )\n",
    "    ray_origin_local = mi.Vector3f(x, y, 0)\n",
    "    ray_origin = mi.Frame3f(cam_dir).to_world(ray_origin_local) + cam_origin\n",
    "    ray = mi.Ray3f(o=ray_origin, d=cam_dir)\n",
    "    si = scene.ray_intersect(ray)\n",
    "\n",
    "    return si, image_res\n",
    "    \n",
    "# Just mitsuba testing\n",
    "si, res = get_camera_first_bounce(scene)\n",
    "bsdf : mi.cuda_ad_rgb.BSDFPtr = si.bsdf()\n",
    "reflectance = bsdf.eval_diffuse_reflectance(si)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sg_product(axis1: torch.Tensor, sharpness1: torch.Tensor, axis2: torch.Tensor, sharpness2: torch.Tensor):\n",
    "    axis = axis1 * sharpness1 + axis2 * sharpness2 \n",
    "    sharpness = torch.norm(axis, dim=1, keepdim=True)\n",
    "\n",
    "    d = axis1 - axis2\n",
    "    len2 = torch.sum(d * d, dim=1, keepdim=True) \n",
    "\n",
    "    denom = torch.maximum(sharpness + sharpness1 + sharpness2, torch.tensor(torch.finfo(torch.float32).max, device=sharpness.device))\n",
    "    log_amplitude = -sharpness1 * sharpness2 * len2 / denom\n",
    "\n",
    "    axis = axis / torch.maximum(sharpness, torch.tensor(torch.finfo(torch.float32).eps, device=sharpness.device)) \n",
    "\n",
    "    return axis, sharpness, log_amplitude\n",
    "\n",
    "# [Tokuyoshi et al. 2024 \"Hierarchical Light Sampling with Accurate Spherical Gaussian Lighting (Supplementary Document)\" Listing. 5]\n",
    "def upper_sg_clamp_cosine_integral_over_two_pi(sharpness: torch.Tensor):\n",
    "    small_sharpness = sharpness <= 0.5\n",
    "    sharpness_safe = torch.clamp(sharpness, min=1e-6, max=50)  # Ограничение\n",
    "\n",
    "    # Taylor-series approximation for numerical stability.\n",
    "    taylor_series = (\n",
    "        (-1.0 / 362880.0) * sharpness_safe +\n",
    "        (1.0 / 40320.0)\n",
    "    )\n",
    "    taylor_series = taylor_series * sharpness_safe - (1.0 / 5040.0)\n",
    "    taylor_series = taylor_series * sharpness_safe + (1.0 / 720.0)\n",
    "    taylor_series = taylor_series * sharpness_safe - (1.0 / 120.0)\n",
    "    taylor_series = taylor_series * sharpness_safe + (1.0 / 24.0)\n",
    "    taylor_series = taylor_series * sharpness_safe - (1.0 / 6.0)\n",
    "    taylor_series = taylor_series * sharpness_safe + 0.5\n",
    "\n",
    "    integral = torch.where(\n",
    "        small_sharpness, \n",
    "        taylor_series, \n",
    "        (torch.expm1(-sharpness_safe) + sharpness_safe) / (sharpness_safe * sharpness_safe)\n",
    "    )\n",
    "    \n",
    "    return torch.nan_to_num(integral, nan=0.0, posinf=1e6, neginf=-1e6)\n",
    "\n",
    "# [Tokuyoshi et al. 2024 \"Hierarchical Light Sampling with Accurate Spherical Gaussian Lighting (Supplementary Document)\" Listing. 6]\n",
    "def lower_sg_clamp_cosine_integral_over_two_pi(sharpness: torch.Tensor):\n",
    "    sharpness_safe = torch.clamp(sharpness, min=1e-6, max=50)  # Ограничение\n",
    "    e = torch.exp(-sharpness_safe)\n",
    "    small_sharpness = sharpness_safe <= 0.5\n",
    "\n",
    "    # Taylor-series approximation for numerical stability.\n",
    "    taylor_series = (1.0 / 403200.0) * sharpness_safe - (1.0 / 45360.0)\n",
    "    taylor_series = taylor_series * sharpness_safe + (1.0 / 5760.0)\n",
    "    taylor_series = taylor_series * sharpness_safe - (1.0 / 840.0)\n",
    "    taylor_series = taylor_series * sharpness_safe + (1.0 / 144.0)\n",
    "    taylor_series = taylor_series * sharpness_safe - (1.0 / 30.0)\n",
    "    taylor_series = taylor_series * sharpness_safe + (1.0 / 8.0)\n",
    "    taylor_series = taylor_series * sharpness_safe - (1.0 / 3.0)\n",
    "    taylor_series = taylor_series * sharpness_safe + 0.5\n",
    "    taylor_series = e * taylor_series  # Перенос умножения на `e` в конец\n",
    "\n",
    "    integral = torch.where(\n",
    "        small_sharpness,\n",
    "        taylor_series,\n",
    "        e * (-torch.expm1(-sharpness_safe) - sharpness_safe * e) / (sharpness_safe * sharpness_safe)\n",
    "    )\n",
    "\n",
    "    return torch.nan_to_num(integral, nan=0.0, posinf=1e6, neginf=-1e6)\n",
    "\n",
    "# Approximate product integral of an SG and clamped cosine / pi.\n",
    "# [Tokuyoshi et al. 2024 \"Hierarchical Light Sampling with Accurate Spherical Gaussian Lighting (Supplementary Document)\" Listing. 7]\n",
    "def sg_clamp_cosine_product_integral_over_pi(cosine: torch.Tensor, sharpness: torch.Tensor):\n",
    "    A = 2.7360831611272558028247203765204\n",
    "    B = 17.02129778174187535455530451145\n",
    "    C = 4.0100826728510421403939290030394\n",
    "    D = 15.219156263147210594866010069381\n",
    "    E = 76.087896272360737270901154261082\n",
    "\n",
    "    sharpness_safe = torch.clamp(sharpness, min=1e-6, max=50)  # Ограничение sharpness\n",
    "    sqrt_term = 0.5 * ((sharpness_safe * A) * sharpness_safe + B) / (((sharpness_safe + C) * sharpness_safe + D) * sharpness_safe + E)\n",
    "    sqrt_safe = torch.sqrt(torch.clamp(sqrt_term, min=1e-6)) \n",
    "    t = sharpness_safe * sqrt_safe\n",
    "    tz = t * cosine\n",
    "\n",
    "    INV_SQRTPI = 0.56418958354775628694807945156077  \n",
    "    CLAMPING_THRESHOLD = torch.tensor(0.5 * torch.finfo(torch.float32).eps, dtype=torch.float32, device=cosine.device)\n",
    "\n",
    "    erfc_neg_tz = torch.erfc(-tz)\n",
    "    erfc_t = torch.erfc(t)\n",
    "    exp_neg_tz2 = torch.exp(-torch.clamp(tz * tz, max=50))  # Ограничиваем экспоненту\n",
    "    exp_safe = torch.expm1(torch.clamp(t * t * (cosine * cosine - 1.0), min=-50, max=50))  # Ограничиваем expm1\n",
    "\n",
    "    exp_term = torch.where(t.abs() > 1e-6, exp_safe / t, torch.zeros_like(t))\n",
    "\n",
    "    lerp_factor = torch.clamp(\n",
    "        torch.max(\n",
    "            0.5 * (cosine * erfc_neg_tz + erfc_t) - 0.5 * INV_SQRTPI * exp_neg_tz2 * exp_term,\n",
    "            CLAMPING_THRESHOLD\n",
    "        ),\n",
    "        0.0, 1.0\n",
    "    )\n",
    "\n",
    "    lower_integral = lower_sg_clamp_cosine_integral_over_two_pi(sharpness_safe)\n",
    "    upper_integral = upper_sg_clamp_cosine_integral_over_two_pi(sharpness_safe)\n",
    "\n",
    "    return 2.0 * torch.lerp(lower_integral, upper_integral, lerp_factor)\n",
    "\n",
    "def sggx(m: torch.Tensor, roughness_mat: torch.Tensor) -> torch.Tensor:\n",
    "    det = torch.det(roughness_mat).clamp(min=1e-7)  \n",
    "    \n",
    "    roughness_mat_adj = torch.stack([\n",
    "        torch.stack([roughness_mat[..., 1, 1], -roughness_mat[..., 0, 1]], dim=-1),\n",
    "        torch.stack([-roughness_mat[..., 1, 0], roughness_mat[..., 0, 0]], dim=-1)\n",
    "    ], dim=-2)\n",
    "\n",
    "    m_xy = m[..., :2].unsqueeze(-2) \n",
    "    length2 = (m_xy @ roughness_mat_adj @ m_xy.transpose(-2, -1)).squeeze(-1).squeeze(-1) / det + m[..., 2] ** 2\n",
    "    \n",
    "    length2 = length2.clamp(min=1e-4)  \n",
    "    sqrt_det = torch.sqrt(det).clamp(min=1e-4)\n",
    "\n",
    "    denom = sqrt_det * length2 ** 2  \n",
    "    return 1.0 / (math.pi * denom)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Approximate the reflection lobe with an SG lobe for microfacet BRDFs.\n",
    "# [Wang et al. 2009 \"All-Frequency Rendering with Dynamic, Spatially-Varying Reflectance\"]\n",
    "def sgg_reflection_pdf(wi: torch.Tensor, m: torch.Tensor, roughness_mat: torch.Tensor) -> torch.Tensor:\n",
    "    xy = wi[:2]\n",
    "    rough_wi = torch.matmul(roughness_mat, xy)\n",
    "    denom = torch.sqrt(torch.sum(xy * rough_wi) + wi[2] * wi[2])\n",
    "    sggx_tensor = sggx(m, roughness_mat)\n",
    "    return sggx_tensor.unsqueeze(-1) / (4.0 * denom)\n",
    "\n",
    "# Approximate hemispherical integral for a vMF distribution (i.e. normalized SG).\n",
    "# The parameter \"cosine\" is the cosine of the angle between the SG axis and the pole axis of the hemisphere.\n",
    "# [Tokuyoshi et al. 2024 \"Hierarchical Light Sampling with Accurate Spherical Gaussian Lighting (Supplementary Document)\" Listing. 4]\n",
    "def vmf_hemispherical_integral(cosine : torch.Tensor, sharpness : torch.Tensor):\n",
    "    cosine = cosine.unsqueeze(-1)\n",
    "    # interpolation factor [Tokuyoshi 2022].\n",
    "    A = 0.6517328826907056171791055021459\n",
    "    B = 1.3418280033141287699294252888649\n",
    "    C = 7.2216687798956709087860872386955\n",
    "    steepness = sharpness * torch.sqrt((0.5 * sharpness + A) / ((sharpness + B) * sharpness + C))\n",
    "    lerp_factor = torch.clamp(0.5 + 0.5 * (torch.erf(steepness * torch.clamp(cosine, -1.0, 1.0)) / torch.erf(steepness)), 0, 1)\n",
    "\n",
    "    # Interpolation between upper and lower hemispherical integrals\n",
    "    e = torch.exp(-sharpness)\n",
    "    one_tensor = torch.tensor(1.0, device=e.device, dtype=e.dtype) \n",
    "    return torch.lerp(e, one_tensor, lerp_factor) / (e + 1.0)\n",
    "\n",
    "def luminance(color: torch.Tensor):\n",
    "    weights = torch.tensor([0.2126, 0.7152, 0.0722], device=color.device)\n",
    "    return torch.sum(color * weights, dim=1) \n",
    "\n",
    "def compute_jacobian(wi_tensor: torch.Tensor):\n",
    "    vlen = torch.linalg.norm(wi_tensor[:, :2], dim=1, keepdim=True)  \n",
    "\n",
    "    v = torch.where(\n",
    "        vlen == 0,\n",
    "        torch.tensor([[1.0, 0.0]], device=wi_tensor.device, dtype=wi_tensor.dtype).expand(wi_tensor.shape[0], -1),\n",
    "        wi_tensor[:, :2] / vlen\n",
    "    ) \n",
    "\n",
    "    rot_mat = torch.stack([\n",
    "        torch.stack([v[:, 0], -v[:, 1]], dim=-1),  \n",
    "        torch.stack([v[:, 1],  v[:, 0]], dim=-1)   \n",
    "    ], dim=1)  \n",
    "\n",
    "    scale_mat = torch.stack([\n",
    "        torch.full((wi_tensor.shape[0], 2), 0.5, device=wi_tensor.device, dtype=wi_tensor.dtype),\n",
    "        torch.stack([torch.zeros_like(wi_tensor[:, 2]), 0.5 / wi_tensor[:, 2]], dim=-1)\n",
    "    ], dim=1)  \n",
    "    jacobian_mat = torch.matmul(rot_mat, scale_mat)\n",
    "    jj_mat = torch.matmul(jacobian_mat, jacobian_mat.transpose(1, 2))\n",
    "\n",
    "    return jj_mat\n",
    "\n",
    "\n",
    "\n",
    "def isotropic_ndf_filtering(si: mi.SurfaceInteraction3f):\n",
    "    SIGMA2 = 0.15915494  # Variance of pixel filter kernel (1/(2pi))\n",
    "    KAPPA = 0.18 \n",
    "\n",
    "    dndu = torch.from_numpy(si.dn_du.numpy()).to(\"cuda\").T\n",
    "    dndv = torch.from_numpy(si.dn_dv.numpy()).to(\"cuda\").T\n",
    "    mask = si.is_valid()\n",
    "    roughness = torch.tensor(si.bsdf().eval_attribute_1(\"roughness\", si, mask), dtype=torch.float32).unsqueeze(-1)  \n",
    "\n",
    "    # Eq. 14 \n",
    "    kernel_roughness2 = SIGMA2 * (torch.sum(dndu * dndu, dim=-1) + torch.sum(dndv * dndv, dim=-1))  \n",
    "    kernel_roughness2 = kernel_roughness2.unsqueeze(-1)\n",
    "    clamped_kernel_roughness2 = torch.clamp(kernel_roughness2, max=KAPPA)\n",
    "    filtered_roughness2 = torch.clamp(roughness**2 + clamped_kernel_roughness2, min=0.0, max=1.0) \n",
    "\n",
    "    return torch.sqrt(filtered_roughness2) \n",
    "\n",
    "def compute_filtered_roughness_mat(filtered_proj_roughness_mat, tr, det):\n",
    "    FLT_MAX = torch.finfo(torch.float32).max \n",
    "\n",
    "    denom = 1.0 + tr + det\n",
    "    is_finite = torch.isfinite(denom)\n",
    "\n",
    "    det_mat = torch.zeros_like(filtered_proj_roughness_mat)\n",
    "    det_mat[:, 0, 0] = det\n",
    "    det_mat[:, 1, 1] = det\n",
    "\n",
    "    mat1 = torch.clamp(filtered_proj_roughness_mat + det_mat, max=FLT_MAX) / denom.unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "    mat2 = torch.zeros_like(filtered_proj_roughness_mat)\n",
    "    mat2[:, 0, 0] = torch.clamp(filtered_proj_roughness_mat[:, 0, 0], max=FLT_MAX) / torch.clamp(filtered_proj_roughness_mat[:, 0, 0] + 1.0, max=FLT_MAX)\n",
    "    mat2[:, 1, 1] = torch.clamp(filtered_proj_roughness_mat[:, 1, 1], max=FLT_MAX) / torch.clamp(filtered_proj_roughness_mat[:, 1, 1] + 1.0, max=FLT_MAX)\n",
    "\n",
    "    return torch.where(is_finite.unsqueeze(-1).unsqueeze(-1), mat1, mat2)\n",
    "\n",
    "\n",
    "# (exp(x) - 1)/x with cancellation of rounding errors.\n",
    "# [Nicholas J. Higham \"Accuracy and Stability of Numerical Algorithms\", Section 1.14.1, p. 19]\n",
    "def expm1_over_x(x: torch.Tensor) -> torch.Tensor:\n",
    "    y = torch.expm1(x) \n",
    "    result = y / x\n",
    "    result = torch.where(torch.abs(x) < 1.0, y / x, result)\n",
    "    return result\n",
    "          \n",
    "def sg_integral(sharpness):\n",
    "    return 4.0 * torch.pi * expm1_over_x(-2.0 * sharpness)\n",
    "\n",
    "def orthonormal_basis(axis: torch.Tensor):\n",
    "    s = torch.where(axis[:, 2] >= 0.0, 1.0, -1.0)  \n",
    "    c = -1.0 / (s + axis[:, 2])  \n",
    "    b = axis[:, 0] * axis[:, 1] * c  \n",
    "    b1 = torch.stack([\n",
    "        1.0 + s * axis[:, 0] * axis[:, 0] * c,\n",
    "        s * b,\n",
    "        -s * axis[:, 0]\n",
    "    ], dim=1)  \n",
    "    b2 = torch.stack([\n",
    "        b,\n",
    "        s + axis[:, 1] * axis[:, 1] * c,\n",
    "        -axis[:, 1]\n",
    "    ], dim=1)  \n",
    "\n",
    "    return torch.stack([b1, b2, axis], dim=1) \n",
    "\n",
    "def sample_vmf(axis: torch.Tensor, sharpness: torch.Tensor):\n",
    "    rand = torch.rand((axis.shape[0], 2), dtype=axis.dtype, device=axis.device) \n",
    "    phi = 2.0 * math.pi * rand[:, 0] \n",
    "    THRESHOLD = torch.finfo(torch.float32).eps / 4.0\n",
    "\n",
    "    mask = sharpness.squeeze(-1) > THRESHOLD \n",
    "    r = torch.empty_like(sharpness.squeeze(-1))\n",
    "\n",
    "    r[mask] = torch.log1p(rand[mask, 1] * torch.expm1(-2.0 * sharpness[mask, 0])) / sharpness[mask, 0]\n",
    "    r[~mask] = -2.0 * rand[~mask, 1]\n",
    "\n",
    "    cos_theta = 1.0 + r \n",
    "    sin_theta = torch.sqrt(-r * r - 2.0 * r) \n",
    "\n",
    "    dir = torch.stack([\n",
    "        torch.cos(phi) * sin_theta,  \n",
    "        torch.sin(phi) * sin_theta,  \n",
    "        cos_theta                    \n",
    "    ], dim=1) \n",
    "\n",
    "    frame = orthonormal_basis(axis)\n",
    "\n",
    "    return torch.einsum('nij,nj->ni', frame, dir) \n",
    "\n",
    "def batched_matmul(A, B, batch_size=1024):\n",
    "    N = A.shape[0] \n",
    "    result = []\n",
    "\n",
    "    for i in range(0, N, batch_size):\n",
    "        batch_A = A[i : i + batch_size] \n",
    "        batch_B = B[i : i + batch_size] \n",
    "        \n",
    "        batch_result = torch.bmm(batch_A, batch_B)\n",
    "        result.append(batch_result)\n",
    "\n",
    "    return torch.cat(result, dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BSDF Approximations: Diffuse as CosineLobeSG, Specular as AnisotropicSG\n",
    "class cosine_lobe_sg:\n",
    "    def __init__(self, direction : torch.Tensor):\n",
    "        self.axis = direction\n",
    "        self.sharpness = torch.full((direction.shape[0], 1), 2.123, device=direction.device, dtype=direction.dtype)\n",
    "        self.amplitude = torch.full((direction.shape[0], 1), 1.17, device=direction.device, dtype=direction.dtype)\n",
    "\n",
    "class anisotropic_lobe_sg:\n",
    "    def __init__(self, axis : torch.Tensor, sharpness : torch.Tensor, log_amplitude : torch.Tensor):\n",
    "        self.axis = axis\n",
    "        self.sharpness = sharpness\n",
    "        self.log_amplitude = log_amplitude\n",
    "\n",
    "# vMF-vMF convolution\n",
    "def A3(kappa):\n",
    "    return 1 / torch.tanh(kappa) - 1 / kappa\n",
    "\n",
    "def dA3(kappa):\n",
    "    csch = 2.0 / (torch.exp(kappa) - torch.exp(-kappa))\n",
    "    return 1 / (kappa ** 2) - csch ** 2\n",
    "\n",
    "def A3inv(y, guess):\n",
    "    x = guess.clone()\n",
    "    residual = torch.zeros_like(y)\n",
    "    \n",
    "    while True:\n",
    "        residual = A3(x) - y\n",
    "        deriv = dA3(x)\n",
    "        x = x - residual / deriv\n",
    "        if torch.max(torch.abs(residual)) < 1e-5:\n",
    "            break\n",
    "    \n",
    "    return x\n",
    "\n",
    "# how to make it correctly?\n",
    "def convolve_vmfs(kappa1, kappa2):\n",
    "    return A3inv(A3(kappa1) * A3(kappa2), torch.minimum(kappa1, kappa2))\n",
    "\n",
    "\n",
    "def approximate_bsdf_with_vmf(bsdf : mi.BSDFPtr, normal : torch.Tensor, view_dir : torch.Tensor, roughness2 : torch.Tensor):\n",
    "    num_interactions = normal.shape[0]\n",
    "\n",
    "    bsdf_eval = bsdf.flags()\n",
    "    \n",
    "    has_diffuse = (bsdf_eval & int(mi.BSDFFlags.Diffuse.value)) != 0\n",
    "    has_specular = (bsdf_eval & int(mi.BSDFFlags.Glossy.value)) != 0\n",
    "\n",
    "    mask_diffuse = torch.from_numpy(has_diffuse.numpy()).to(\"cuda\").T\n",
    "    mask_specular = torch.from_numpy(has_specular.numpy()).to(\"cuda\").T\n",
    "\n",
    "    mask_random = torch.randint(0, 2, (num_interactions,), dtype=torch.bool, device=\"cuda\")\n",
    "    mask_final = mask_diffuse & mask_specular\n",
    "    mask_diffuse = mask_diffuse & ~mask_final | (mask_final & mask_random)\n",
    "    mask_specular = mask_specular & ~mask_final | (mask_final & ~mask_random)\n",
    "\n",
    "    axis = torch.zeros((num_interactions, 3), device=normal.device)\n",
    "    sharpness = torch.zeros((num_interactions, 2), device=normal.device)  \n",
    "    amplitude = torch.zeros((num_interactions, 1), device=normal.device)\n",
    "\n",
    "    if mask_diffuse.any():\n",
    "        lobes_diffuse = cosine_lobe_sg(normal[mask_diffuse])\n",
    "        axis[mask_diffuse] = lobes_diffuse.axis\n",
    "        sharpness[mask_diffuse, 0] = lobes_diffuse.sharpness.squeeze(-1) \n",
    "        amplitude[mask_diffuse] = lobes_diffuse.amplitude\n",
    "\n",
    "    if mask_specular.any():\n",
    "        lobes_specular = anisotropic_lobe_sg(view_dir[mask_specular], normal[mask_specular], roughness2[mask_specular])\n",
    "        axis[mask_specular] = lobes_specular.axis\n",
    "        sharpness[mask_specular] = lobes_specular.sharpness\n",
    "        amplitude[mask_specular] = lobes_specular.log_amplitude\n",
    "\n",
    "    return axis, sharpness, amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class vapl_mixture:\n",
    "    def __init__(self, gaussians : torch.Tensor, vmfs : torch.Tensor):\n",
    "        self.mean      : torch.Tensor = gaussians[:, :3]\n",
    "        self.variance  : torch.Tensor = gaussians[:, 3]\n",
    "        self.sharpness : torch.Tensor = vmfs[:, 0]\n",
    "        self.axis      : torch.Tensor = vmfs[:, 1:4]\n",
    "        self.amplitude : torch.Tensor = vmfs[:, 4:7]\n",
    "\n",
    "        self.normalized_vapl_weights = torch.ones(gaussians.shape[0])\n",
    "        self.num_rays = gaussians.shape[0]\n",
    "    \n",
    "    def calculate_normalized_vapl_weights(self, si : mi.SurfaceInteraction3f):\n",
    "        weights = self.convolve_with_bsdf(si) \n",
    "        total_weight = torch.sum(weights) \n",
    "        self.normalized_vapl_weights = weights / total_weight  \n",
    "    \n",
    "    def sample_vapl(self, si : mi.SurfaceInteraction3f):\n",
    "        self.calculate_normalized_vapl_weights(si)\n",
    "        indices = torch.multinomial(self.normalized_vapl_weights, num_samples=self.num_rays, replacement=True)\n",
    "        \n",
    "        self.mean       = self.mean[indices]\n",
    "        self.variance   = self.variance[indices]\n",
    "        self.sharpness  = self.sharpness[indices]\n",
    "        self.axis       = self.axis[indices]\n",
    "        self.amplitude  = self.amplitude[indices]\n",
    "        self.light_lobe = self.light_lobe[indices]\n",
    "        return self\n",
    "\n",
    "\n",
    "    def convolve_with_bsdf(self, si : mi.SurfaceInteraction3f):\n",
    "        SGLIGHT_SHARPNESS_MAX = float.fromhex(\"0x1.0p41\")\n",
    "        \n",
    "        position  = si.p\n",
    "        normal    = si.n\n",
    "        tangent   = si.dp_du\n",
    "        bitangent = si.dp_dv\n",
    "\n",
    "        pos_tensor  = torch.from_numpy(position.numpy()).to(\"cuda\").T\n",
    "        norm_tensor = torch.from_numpy(normal.numpy()).to(\"cuda\").T\n",
    "        tangent_frame = mi.Frame3f(tangent, bitangent, normal)\n",
    "        \n",
    "        light_vec = self.mean - pos_tensor\n",
    "        squared_distance = torch.sum(light_vec * light_vec, dim=1).unsqueeze(1)\n",
    "        light_dir = light_vec * torch.rsqrt(squared_distance)\n",
    "        \n",
    "        # clamp variance for the numerical stability\n",
    "        self.variance = self.variance.unsqueeze(1)\n",
    "        variance = torch.max(self.variance, squared_distance / SGLIGHT_SHARPNESS_MAX)\n",
    "        \n",
    "        # compute the maximum emissive radiance of the vapl.\n",
    "        emissive = self.amplitude / variance\n",
    "        \n",
    "        # compute vapl sharpness for a light distribution viewed from the shading point.\n",
    "        light_sharpness = squared_distance / variance\n",
    "        self.sharpness = self.sharpness.unsqueeze(1)\n",
    "        \n",
    "        # light lobe given by the product of the light distribution viewed \n",
    "        # from the shading point and the directional distribution of the vapl.\n",
    "        light_lobe_axis, light_lobe_sharpness, light_lobe_log_amplitude = sg_product(\n",
    "            self.axis, self.sharpness, light_dir, light_sharpness)\n",
    "        self.light_lobe = torch.cat([light_lobe_axis, light_lobe_sharpness, light_lobe_log_amplitude], dim=1)\n",
    "        \n",
    "        # bsdf at the current intersection\n",
    "        bsdf: mi.cuda_ad_rgb.BSDFPtr = si.bsdf()\n",
    "        \n",
    "        # Create BSDF contexts\n",
    "        ctx_diffuse = mi.BSDFContext()\n",
    "        ctx_diffuse.type_mask = mi.BSDFFlags.Diffuse\n",
    "        ctx_specular = mi.BSDFContext()\n",
    "        ctx_specular.type_mask = mi.BSDFFlags.Glossy\n",
    "        \n",
    "        # Local outgoing direction\n",
    "        wo = si.to_local(-si.wi)\n",
    "\n",
    "        diffuse = bsdf.eval(ctx_diffuse, si, wo)\n",
    "        specular = bsdf.eval(ctx_specular, si, wo)\n",
    "        \n",
    "        # Diffuse SG lighting.\n",
    "\t\t# [Tokuyoshi et al. 2024 \"Hierarchical Light Sampling with Accurate Spherical Gaussian Lighting\", Section 4]\n",
    "        amplitude = torch.exp(light_lobe_log_amplitude)\n",
    "        cosine = torch.clamp(torch.sum(light_lobe_axis * norm_tensor, dim=1), -1.0, 1.0).unsqueeze(1)\n",
    "        \n",
    "        diffuse_illumination = amplitude * sg_clamp_cosine_product_integral_over_pi(cosine, light_lobe_sharpness)\n",
    "        diffuse_tensor = torch.stack([\n",
    "            torch.from_numpy(diffuse.x.numpy()).to(\"cuda\"),\n",
    "            torch.from_numpy(diffuse.y.numpy()).to(\"cuda\"),\n",
    "            torch.from_numpy(diffuse.z.numpy()).to(\"cuda\")\n",
    "        ], dim=1)\n",
    "\n",
    "        specular_tensor =torch.stack([\n",
    "            torch.from_numpy(specular.x.numpy()).to(\"cuda\"),\n",
    "            torch.from_numpy(specular.y.numpy()).to(\"cuda\"),\n",
    "            torch.from_numpy(specular.z.numpy()).to(\"cuda\")\n",
    "        ], dim=1)\n",
    "        \n",
    "        diffuse_illumination_result = diffuse_tensor * diffuse_illumination\n",
    "        \n",
    "        # Compute JJ^T for NDF filtering.\n",
    "        wi = si.wi\n",
    "        wi_tensor = torch.from_numpy(wi.numpy()).to(\"cuda\").T \n",
    "        jj_mat = compute_jacobian(wi_tensor)\n",
    "\n",
    "        # Compute determinant of JJ^T \n",
    "        eps = torch.finfo(torch.float32).eps\n",
    "\n",
    "        wi_z = torch.from_numpy(wi.z.numpy()).to(\"cuda\")\n",
    "        det_jj4 = 1.0 / (4.0 * wi_z * wi_z)\n",
    "        roughness = isotropic_ndf_filtering(si)\n",
    "        roughness2 = roughness**2\n",
    "        proj_roughness2 = roughness2 / torch.maximum(1.0 - roughness2, torch.tensor(eps, device=roughness2.device))\n",
    "        reflect_sharpness = (1.0 - roughness2) / torch.maximum(2.0 * roughness2, torch.tensor(eps, device=roughness2.device))\n",
    "        reflect_vec_tensor = torch.from_numpy(mi.reflect(si.wi, normal).numpy()).to(\"cuda\").T\n",
    "        reflect_vec = reflect_vec_tensor * reflect_sharpness\n",
    "\n",
    "        # Glossy SG lighting.\n",
    "\t\t# [Tokuyoshi et al. 2024 \"Hierarchical Light Sampling with Accurate Spherical Gaussian Lighting\", Section 5]\n",
    "        prod_vec = reflect_vec + light_lobe_axis * light_lobe_sharpness\n",
    "        prod_sharpness = torch.linalg.norm(prod_vec, dim=1, keepdim=True)\n",
    "        prod_dir = prod_vec / prod_sharpness\n",
    "        \n",
    "        light_lobe_variance = 1.0 / light_lobe_sharpness\n",
    "        diag_proj_roughness = torch.diag_embed(proj_roughness2.expand(-1, 2)) + 2.0\n",
    "\n",
    "        filtered_proj_roughness_mat = batched_matmul(diag_proj_roughness * light_lobe_variance.unsqueeze(-1), jj_mat)\n",
    "        \n",
    "        proj_roughness2 = (roughness2 / torch.maximum(1.0 - roughness2, torch.tensor(eps, device=roughness2.device))).expand(-1, 2)\n",
    "\n",
    "        # Compute the determinant of filteredProjRoughnessMat in a numerically stable manner.\n",
    "\t\t# See the supplementary document (Section 5.2) of the paper for the derivation.\n",
    "        det = (proj_roughness2[:, 0] * proj_roughness2[:, 1] + 2.0 * light_lobe_variance.squeeze(-1) \n",
    "               * (proj_roughness2[:, 0] * jj_mat[:, 0, 0] + proj_roughness2[:, 1] * jj_mat[:, 1, 1]) \n",
    "               + light_lobe_variance.squeeze(-1) ** 2 * det_jj4.squeeze(-1))\n",
    "        \n",
    "        # NDF filtering in a numerically stable manner\n",
    "        # See the supplementary document (Section 5.2) of the paper for the derivation\n",
    "        tr = torch.einsum(\"bii->b\", filtered_proj_roughness_mat)\n",
    "        filtered_roughness_mat = compute_filtered_roughness_mat(filtered_proj_roughness_mat, tr, det)\n",
    "\n",
    "        # visibility of the SG light in the upper hemisphere.\n",
    "        visibility = vmf_hemispherical_integral(torch.sum(prod_dir * norm_tensor, dim=1), prod_sharpness)\n",
    "        \n",
    "        # evaluate the filtered reflection lobe\n",
    "        light_lobe_axis_mi = tangent_frame.to_local(mi.cuda_ad_rgb.Vector3f(light_lobe_axis.permute(1, 0)))\n",
    "        light_lobe_axis = torch.from_numpy(light_lobe_axis_mi.numpy()).to(\"cuda\").T\n",
    "        half_vec_unnormalize = wi_tensor + light_lobe_axis\n",
    "        half_vec = half_vec_unnormalize / torch.maximum(torch.norm(half_vec_unnormalize), torch.tensor(torch.finfo(torch.float32).eps))\n",
    "        \n",
    "        lobe = sgg_reflection_pdf(wi_tensor, half_vec, filtered_roughness_mat)\n",
    "        \n",
    "        specular_illumination = amplitude * visibility * lobe * sg_integral(light_lobe_sharpness)\n",
    "        specular_illumination_result = specular_tensor * specular_illumination\n",
    "\n",
    "        result = emissive * (diffuse_illumination_result + specular_illumination_result)\n",
    "\n",
    "        # Store illumination to calculate Loss later\n",
    "        self.diffuse_illumination = diffuse_illumination_result\n",
    "        self.specular_illumination = specular_illumination_result\n",
    "        self.illumination = result\n",
    "\n",
    "        # Calculate BSDF approximations with vMF\n",
    "        view_dir = torch.from_numpy(wo.numpy()).to(\"cuda\").T # ? not sure\n",
    "        self.bsdf_axis, self.bsdf_sharpness, self.bsdf_amplitude = approximate_bsdf_with_vmf(bsdf, norm_tensor, view_dir, roughness2)\n",
    "        \n",
    "        return luminance(result)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is possible to just use render_rhs and RHSIntegrator from \n",
    "# https://github.com/krafton-ai/neural-radiosity-tutorial-mitsuba3/blob/main/neural_radiosity.ipynb\n",
    "\n",
    "@dr.syntax\n",
    "def first_non_specular_or_null_si(scene, si, sampler):\n",
    "    \"\"\"Find the first non-specular or null surface interaction.\"\"\"\n",
    "    with dr.suspend_grad():\n",
    "        bsdf_ctx = mi.BSDFContext()\n",
    "        depth = mi.UInt32(0)\n",
    "        β = mi.Spectrum(1)\n",
    "        bsdf = si.bsdf()\n",
    "        \n",
    "        null_face = ~mi.has_flag(si.bsdf().flags(), mi.BSDFFlags.BackSide) & (si.wi.z < 0)\n",
    "        active = si.is_valid() & ~null_face  # non-null surface\n",
    "        active &= ~mi.has_flag(si.bsdf().flags(), mi.BSDFFlags.Smooth)  # Delta surface\n",
    "\n",
    "        max_depth = 6\n",
    "        \n",
    "        while active & (depth < max_depth):\n",
    "            bsdf_sample, bsdf_weight = bsdf.sample(\n",
    "                bsdf_ctx, si, sampler.next_1d(), sampler.next_2d(), active\n",
    "            )\n",
    "            ray = si.spawn_ray(si.to_world(bsdf_sample.wo))\n",
    "            si = scene.ray_intersect(\n",
    "                ray, ray_flags=mi.RayFlags.All, coherent=depth == 0\n",
    "            )\n",
    "            bsdf = si.bsdf(ray)\n",
    "            \n",
    "            β *= bsdf_weight\n",
    "            depth[si.is_valid()] += 1\n",
    "\n",
    "            null_face &= ~mi.has_flag(bsdf.flags(), mi.BSDFFlags.BackSide) & (si.wi.z < 0)\n",
    "            active &= si.is_valid() & ~null_face\n",
    "            active &= ~mi.has_flag(bsdf.flags(), mi.BSDFFlags.Smooth)\n",
    "\n",
    "    return si, β, null_face\n",
    "\n",
    "\n",
    "def render_rhs(scene : mi.Scene, model : vapl_grid, si : mi.SurfaceInteraction3f, sampler):\n",
    "    with dr.suspend_grad():\n",
    "        # get the vapl mixture for this intersection\n",
    "        gaussians, vmfs = model(si)\n",
    "        mixture = vapl_mixture(gaussians, vmfs)\n",
    "        sampled_vapls = mixture.sample_vapl(si)\n",
    "\n",
    "        # Calculating new sample direction\n",
    "        # 1st option - Sample direction from sampled vapl light lobe\n",
    "        light_lobe = sampled_vapls.light_lobe\n",
    "        light_lobe_axis, light_lobe_sharpness, light_lobe_log_amplitude = torch.split(light_lobe, [3, 1, 1], dim=1)\n",
    "        sampled_dir : torch.Tensor = sample_vmf(light_lobe_axis, light_lobe_sharpness)\n",
    "\n",
    "        # 2nd option - Sample direction according to BSDF x vapl convolution\n",
    "        # Specular BSDF - Anisotropic Spherical Gaussian\n",
    "        # Diffuse BSDF  - Cosine Lobe\n",
    "        # vapl_mixture stores self.bsdf_axis, self.bsdf_sharpness, self.bsdf_amplitude\n",
    "        # need to convolve it correctly with light_lobe\n",
    "        # and after that call sample_vmf\n",
    "\n",
    "        # All the stuff from original render_rhs function\n",
    "        bsdf_ctx = mi.BSDFContext()\n",
    "        depth = mi.UInt32(0)\n",
    "        L = mi.Spectrum(0)\n",
    "        β = mi.Spectrum(1)\n",
    "        η = mi.Float(1)\n",
    "        prev_si = dr.zeros(mi.SurfaceInteraction3f)\n",
    "        prev_bsdf_pdf = mi.Float(1.0)\n",
    "        prev_bsdf_delta = mi.Bool(True)\n",
    "\n",
    "        bsdf = si.bsdf()\n",
    "        Le = β * si.emitter(scene).eval(si)\n",
    "\n",
    "        # emitter sampling\n",
    "        active_next = si.is_valid()\n",
    "        active_em = active_next & mi.has_flag(bsdf.flags(), mi.BSDFFlags.Smooth)\n",
    "        \n",
    "        ds, em_weight = scene.sample_emitter_direction(\n",
    "            si, sampler.next_2d(), True, active_em\n",
    "        )\n",
    "        active_em &= (ds.pdf != 0.0)\n",
    "        \n",
    "        wo = si.to_local(ds.d)\n",
    "        bsdf_value_em, bsdf_pdf_em = bsdf.eval_pdf(bsdf_ctx, si, wo, active_em)\n",
    "        mis_em = dr.select(ds.delta, 1, mis_weight(ds.pdf, bsdf_pdf_em))\n",
    "        Lr_dir = β * mis_em * bsdf_value_em * em_weight\n",
    "\n",
    "        # bsdf sampling\n",
    "        bsdf_sample, bsdf_weight = bsdf.sample(\n",
    "            bsdf_ctx, si, sampler.next_1d(), sampler.next_2d(), active_next\n",
    "        )\n",
    "        \n",
    "        # update\n",
    "        L = L + Le + Lr_dir\n",
    "\n",
    "        # Use new direction from vapl mixture\n",
    "        permute_sampled_dir = sampled_dir.permute(1, 0)\n",
    "        new_dir = mi.cuda_ad_rgb.Vector3f(permute_sampled_dir)\n",
    "        ray = si.spawn_ray(si.to_world(new_dir))\n",
    "\n",
    "        η = bsdf_sample.eta\n",
    "        β *= bsdf_weight\n",
    "        \n",
    "        prev_si = dr.detach(si, True)\n",
    "        prev_bsdf_pdf = bsdf_sample.pdf\n",
    "        prev_bsdf_delta = mi.has_flag(bsdf_sample.sampled_type, mi.BSDFFlags.Delta)\n",
    "        \n",
    "        si = scene.ray_intersect(ray, ray_flags=mi.RayFlags.All, coherent=True)\n",
    "        ds = mi.DirectionSample3f(scene, si=si, ref=prev_si)\n",
    "        \n",
    "        mis = mis_weight(\n",
    "            prev_bsdf_pdf,\n",
    "            scene.pdf_emitter_direction(prev_si, ds, ~prev_bsdf_delta),\n",
    "        )\n",
    "\n",
    "        si, β2, null_face = first_non_specular_or_null_si(scene, si, sampler)\n",
    "        β *= β2\n",
    "\n",
    "        L += β * mis * si.emitter(scene).eval(si) # Li (x1, wo)\n",
    "\n",
    "        L_tensor = torch.from_numpy(L.numpy()).to(\"cuda\").T\n",
    "        light_from_vapl = sampled_vapls.illumination\n",
    "        \n",
    "        mse_loss_func = torch.nn.MSELoss()\n",
    "        loss = mse_loss_func(light_from_vapl, L_tensor)\n",
    "        loss.backward()\n",
    "        model.sg_optimizer.step()\n",
    "        model.vmf_optimizer.step()\n",
    "        model.sg_optimizer.zero_grad()\n",
    "        model.vmf_optimizer.zero_grad()\n",
    "\n",
    "        return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RHSIntegrator(ADIntegrator):\n",
    "    def __init__(self, model, props=mi.Properties()):\n",
    "        super().__init__(props)\n",
    "        self.model = model\n",
    "\n",
    "    @dr.syntax\n",
    "    def sample(self,\n",
    "               mode: dr.ADMode,\n",
    "               scene: mi.Scene,\n",
    "               sampler: mi.Sampler,\n",
    "               ray: mi.Ray3f,\n",
    "               depth: mi.UInt32,\n",
    "               δL,\n",
    "               δaovs,\n",
    "               state_in,\n",
    "               active):\n",
    "        w, h = list(scene.sensors()[0].film().size())\n",
    "        L = mi.Spectrum(0)\n",
    "\n",
    "        ray = mi.Ray3f(dr.detach(ray))\n",
    "        si = scene.ray_intersect(\n",
    "            ray, ray_flags=mi.RayFlags.All, coherent=(depth == 0)\n",
    "        )\n",
    "\n",
    "        # update si and bsdf with the first non-specular ones\n",
    "        si, β, _ = first_non_specular_or_null_si(scene, si, sampler)\n",
    "        L = render_rhs(scene, self.model, si, sampler)\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        return β * L, si.is_valid(), [], mi.Spectrum(0)  \n",
    "\n",
    "# test that vapl grid and mixture works\n",
    "field = vapl_grid(scene.bbox().min, scene.bbox().max, 4, 4, 8).cuda()\n",
    "\n",
    "rhs_integrator = RHSIntegrator(field)\n",
    "rhs_image = mi.render(scene, spp=32, integrator=rhs_integrator)\n",
    "lhs_image = mi.render(scene, spp=32)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "ax[0].imshow(np.clip(lhs_image ** (1.0 / 2.2), 0, 1))\n",
    "ax[0].set_title(\"Mitsuba Path Integrator\")\n",
    "ax[0].axis(\"off\")\n",
    "\n",
    "ax[1].imshow(np.clip(rhs_image ** (1.0 / 2.2), 0, 1))\n",
    "ax[1].set_title(\"VAPL Grid Integrator\")\n",
    "ax[1].axis(\"off\")\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
