{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import drjit as dr\n",
    "import mitsuba as mi\n",
    "\n",
    "mi.set_variant(\"cuda_ad_rgb\")\n",
    "\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from mitsuba.python.ad.integrators.common import ADIntegrator, mis_weight\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "import tinycudann as tcnn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default cornell box\n",
    "scene_dict = mi.cornell_box()\n",
    "scene = mi.load_dict(scene_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In relation to Hierachical Light Sampling paper by AMD, light is going to be represented as pair of Gaussian + vMF\n",
    "    * Isotropic Gaussian, approximates the light positions distirbution\n",
    "        μ - mean (centre of Gaussian)\n",
    "        σ2 - variance (spread of distribution)\n",
    "    * vMF, approximates directional distirbution of radiant intensity (Normalized Gaussian)\n",
    "        κ - sharpness\n",
    "        ν - axis\n",
    "        α - amplitude\n",
    "\n",
    "So final struct that we have:\n",
    "[\n",
    "    vec3  mean\n",
    "    float variance\n",
    "    float sharpness\n",
    "    vec3  axis\n",
    "    vec3  amplitude\n",
    "]\n",
    "\n",
    "Going to call Gaussian vMF pair - Virtual Anisotropic Point Light - VAPL\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class vapl_grid(torch.nn.Module):\n",
    "    def __init__(self, bb_min, bb_max, num_gaussian_in_mixture, num_param_per_gaussian, num_param_per_vmf):\n",
    "        super().__init__()\n",
    "\n",
    "        self.bb_min = bb_min\n",
    "        self.bb_max = bb_max\n",
    "\n",
    "        # tiny-cuda-nn config for hash grid\n",
    "        config = {\n",
    "            \"encoding\": {\n",
    "                \"otype\": \"HashGrid\",\n",
    "                \"base_resolution\": 16,\n",
    "                \"n_levels\": num_gaussian_in_mixture,\n",
    "                \"n_features_per_level\": num_param_per_gaussian,\n",
    "                \"log2_hashmap_size\": 22,\n",
    "            },\n",
    "        }\n",
    "        n_input_dims = 3\n",
    "        self.gaussian_grid = tcnn.Encoding(n_input_dims, config[\"encoding\"])\n",
    "\n",
    "        config[\"encoding\"][\"n_features_per_level\"] = num_param_per_vmf\n",
    "        self.vmf_grid = tcnn.Encoding(n_input_dims, config[\"encoding\"])\n",
    "        \n",
    "\n",
    "    def forward(self, si):\n",
    "        with dr.suspend_grad():\n",
    "            # get the position of ray-scene intersection in scene bb\n",
    "            X = ((si.p - self.bb_min) / (self.bb_max - self.bb_min)).torch()\n",
    "            gaussians = self.gaussian_grid(X.T)\n",
    "            vmf = self.vmf_grid(X.T)\n",
    "\n",
    "        # mean\n",
    "        eps = 1e-2\n",
    "        gaussians[:,:3] = gaussians[:,:3] / eps * 0.5 + 0.5\n",
    "        # variance\n",
    "        gaussians[:, 3] = torch.relu(gaussians[:, 3]) \n",
    "\n",
    "        # sharpness\n",
    "        vmf[:, 0] = torch.exp(vmf[:, 0])\n",
    "        # axis\n",
    "        norm = torch.norm(vmf[:, 1:4])\n",
    "        vmf[:, 1:4] = vmf[:, 1:4] / norm\n",
    "        # amplitude\n",
    "        vmf[:, 4:7] = torch.relu(vmf[:, 4:7])\n",
    "\n",
    "        return gaussians, vmf    \n",
    "\n",
    "def get_camera_first_bounce(scene):\n",
    "    cam_origin = mi.Point3f(0, 1, 3)\n",
    "    cam_dir = dr.normalize(mi.Vector3f(0, -0.5, -1))\n",
    "    cam_width = 2.0\n",
    "    cam_height = 2.0\n",
    "    image_res = [4, 4]\n",
    "\n",
    "    x, y = dr.meshgrid(\n",
    "        dr.linspace(mi.Float, -cam_width / 2, cam_width / 2, image_res[0]),\n",
    "        dr.linspace(mi.Float, -cam_height / 2, cam_height / 2, image_res[1]),\n",
    "    )\n",
    "    ray_origin_local = mi.Vector3f(x, y, 0)\n",
    "    ray_origin = mi.Frame3f(cam_dir).to_world(ray_origin_local) + cam_origin\n",
    "    ray = mi.Ray3f(o=ray_origin, d=cam_dir)\n",
    "    si = scene.ray_intersect(ray)\n",
    "\n",
    "    return si, image_res\n",
    "    \n",
    "# Just mitsuba testing\n",
    "si, res = get_camera_first_bounce(scene)\n",
    "bsdf : mi.cuda_ad_rgb.BSDFPtr = si.bsdf()\n",
    "reflectance = bsdf.eval_diffuse_reflectance(si)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sg_product(axis1: torch.Tensor, sharpness1: torch.Tensor, axis2: torch.Tensor, sharpness2: torch.Tensor):\n",
    "    axis = axis1 * sharpness1 + axis2 * sharpness2 \n",
    "    sharpness = torch.norm(axis, dim=1, keepdim=True)\n",
    "\n",
    "    d = axis1 - axis2\n",
    "    len2 = torch.sum(d * d, dim=1, keepdim=True) \n",
    "\n",
    "    denom = torch.maximum(sharpness + sharpness1 + sharpness2, torch.tensor(torch.finfo(torch.float32).max, device=sharpness.device))\n",
    "    log_amplitude = -sharpness1 * sharpness2 * len2 / denom\n",
    "\n",
    "    axis = axis / torch.maximum(sharpness, torch.tensor(torch.finfo(torch.float32).eps, device=sharpness.device)) \n",
    "\n",
    "    return axis, sharpness, log_amplitude\n",
    "\n",
    "# [Tokuyoshi et al. 2024 \"Hierarchical Light Sampling with Accurate Spherical Gaussian Lighting (Supplementary Document)\" Listing. 5]\n",
    "def upper_sg_clamp_cosine_integral_over_two_pi(sharpness: torch.Tensor):\n",
    "    small_sharpness = sharpness <= 0.5\n",
    "    sharpness_safe = torch.where(small_sharpness, sharpness, torch.clamp(sharpness, min=1e-6))\n",
    "\n",
    "    # Taylor-series approximation for the numerical stability.\n",
    "    taylor_series = (((((((-1.0 / 362880.0) * sharpness + 1.0 / 40320.0) * sharpness - 1.0 / 5040.0) * sharpness \n",
    "                        + 1.0 / 720.0) * sharpness - 1.0 / 120.0) * sharpness + 1.0 / 24.0) * sharpness - 1.0 / 6.0) * sharpness + 0.5\n",
    "\n",
    "    integral = torch.where(small_sharpness, taylor_series, \n",
    "                           (torch.expm1(-sharpness_safe) + sharpness_safe) / (sharpness_safe * sharpness_safe))\n",
    "    return integral\n",
    "\n",
    "# [Tokuyoshi et al. 2024 \"Hierarchical Light Sampling with Accurate Spherical Gaussian Lighting (Supplementary Document)\" Listing. 6]\n",
    "def lower_sg_clamp_cosine_integral_over_two_pi(sharpness: torch.Tensor):\n",
    "    e = torch.exp(-sharpness)\n",
    "    small_sharpness = sharpness <= 0.5\n",
    "    sharpness_safe = torch.where(small_sharpness, sharpness, torch.clamp(sharpness, min=1e-6))\n",
    "\n",
    "    # Taylor-series approximation for the numerical stability.\n",
    "    taylor_series = e * (((((((((1.0 / 403200.0) * sharpness - 1.0 / 45360.0) * sharpness + 1.0 / 5760.0) * sharpness \n",
    "                               - 1.0 / 840.0) * sharpness + 1.0 / 144.0) * sharpness - 1.0 / 30.0) * sharpness \n",
    "                               + 1.0 / 8.0) * sharpness - 1.0 / 3.0) * sharpness + 0.5)\n",
    "\n",
    "    integral = torch.where(small_sharpness, taylor_series,\n",
    "                           e * (-torch.expm1(-sharpness_safe) - sharpness_safe * e) / (sharpness_safe * sharpness_safe))\n",
    "    return integral\n",
    "\n",
    "# Approximate product integral of an SG and clamped cosine / pi.\n",
    "# [Tokuyoshi et al. 2024 \"Hierarchical Light Sampling with Accurate Spherical Gaussian Lighting (Supplementary Document)\" Listing. 7]\n",
    "def sg_clamp_cosine_product_integral_over_pi(cosine: torch.Tensor, sharpness: torch.Tensor):\n",
    "    A = 2.7360831611272558028247203765204\n",
    "    B = 17.02129778174187535455530451145\n",
    "    C = 4.0100826728510421403939290030394\n",
    "    D = 15.219156263147210594866010069381\n",
    "    E = 76.087896272360737270901154261082\n",
    "\n",
    "    sqrt_term = 0.5 * ((sharpness * A) * sharpness + B) / (((sharpness + C) * sharpness + D) * sharpness + E)\n",
    "    sqrt_safe = torch.sqrt(torch.clamp(sqrt_term, min=1e-6)) \n",
    "    t = sharpness * sqrt_safe\n",
    "    tz = t * cosine\n",
    "\n",
    "    INV_SQRTPI = 0.56418958354775628694807945156077  \n",
    "    CLAMPING_THRESHOLD = torch.tensor(0.5 * torch.finfo(torch.float32).eps, dtype=torch.float32, device=cosine.device)\n",
    "\n",
    "    erfc_neg_tz = torch.erfc(-tz)\n",
    "    erfc_t = torch.erfc(t)\n",
    "    exp_neg_tz2 = torch.exp(-tz * tz)\n",
    "    exp_safe = torch.expm1(t * t * (cosine * cosine - 1.0))\n",
    "\n",
    "    exp_term = torch.where(t.abs() > 1e-6, exp_safe / t, torch.zeros_like(t))\n",
    "\n",
    "    lerp_factor = torch.clamp(\n",
    "        torch.max(\n",
    "            0.5 * (cosine * erfc_neg_tz + erfc_t) - 0.5 * INV_SQRTPI * exp_neg_tz2 * exp_term,\n",
    "            CLAMPING_THRESHOLD\n",
    "        ),\n",
    "        0.0, 1.0\n",
    "    )\n",
    "\n",
    "    lower_integral = lower_sg_clamp_cosine_integral_over_two_pi(sharpness)\n",
    "    upper_integral = upper_sg_clamp_cosine_integral_over_two_pi(sharpness)\n",
    "\n",
    "    return 2.0 * torch.lerp(lower_integral, upper_integral, lerp_factor)\n",
    "\n",
    "def sggx(m, roughness_mat):\n",
    "    det = torch.det(roughness_mat).clamp(min=1e-7)  # FLT_MIN аналогично 1e-7\n",
    "    roughnessMatAdj = torch.tensor([\n",
    "        [roughness_mat[1, 1], -roughness_mat[0, 1]],\n",
    "        [-roughness_mat[1, 0], roughness_mat[0, 0]]\n",
    "    ], device=m.device, dtype=m.dtype)\n",
    "\n",
    "    length2 = (m[:2] @ roughnessMatAdj @ m[:2]) / det + m[2] ** 2\n",
    "\n",
    "    return 1.0 / (math.pi * torch.sqrt(det) * (length2 ** 2))\n",
    "\n",
    "\n",
    "# Approximate the reflection lobe with an SG lobe for microfacet BRDFs.\n",
    "# [Wang et al. 2009 \"All-Frequency Rendering with Dynamic, Spatially-Varying Reflectance\"]\n",
    "def sgg_reflection_pdf(wi, m, roughness_mat):\n",
    "    return sggx(m, roughness_mat) / (4.0 * torch.sqrt(torch.dot()))\n",
    "\n",
    "# Approximate hemispherical integral for a vMF distribution (i.e. normalized SG).\n",
    "# The parameter \"cosine\" is the cosine of the angle between the SG axis and the pole axis of the hemisphere.\n",
    "# [Tokuyoshi et al. 2024 \"Hierarchical Light Sampling with Accurate Spherical Gaussian Lighting (Supplementary Document)\" Listing. 4]\n",
    "def vmf_hemispherical_integral(cosine, sharpness):\n",
    "    # interpolation factor [Tokuyoshi 2022].\n",
    "    A = 0.6517328826907056171791055021459\n",
    "    B = 1.3418280033141287699294252888649\n",
    "    C = 7.2216687798956709087860872386955\n",
    "    steepness = sharpness * torch.sqrt((0.5 * sharpness + A) / ((sharpness + B) * sharpness + C))\n",
    "    lerp_factor = torch.clamp(0.5 + 0.5 * (torch.erf(steepness * torch.clamp(cosine, -1.0, 1.0)) / torch.erf(steepness)), 0, 1)\n",
    "\n",
    "    # Interpolation between upper and lower hemispherical integrals\n",
    "    e = torch.exp(-sharpness)\n",
    "    return torch.lerp(e, 1.0, lerp_factor) / (e + 1.0)\n",
    "\n",
    "def luminance(color: torch.Tensor):\n",
    "    weights = torch.tensor([0.2126, 0.7152, 0.0722], device=color.device)\n",
    "    return torch.sum(color * weights, dim=1) \n",
    "\n",
    "def compute_jacobian(wi):\n",
    "    wi_tensor = torch.from_numpy(wi.numpy()).to(\"cuda\")\n",
    "    vlen = torch.linalg.norm(wi_tensor[:, :2], dim=1)\n",
    "\n",
    "    mask = vlen == 0\n",
    "    v = torch.where(mask.unsqueeze(1),\n",
    "                    torch.tensor([1.0, 0.0], device=wi_tensor.device, dtype=wi_tensor.dtype), \n",
    "                    wi_tensor[:, :2] / vlen.unsqueeze(1))\n",
    "\n",
    "\n",
    "    rot_mat = torch.stack([\n",
    "        torch.stack([v[:, 0], -v[:, 1]], dim=-1),  \n",
    "        torch.stack([v[:, 1],  v[:, 0]], dim=-1)   \n",
    "    ], dim=1)  \n",
    "\n",
    "    scale_mat = torch.stack([\n",
    "        torch.tensor([0.5, 0.0], device=wi_tensor.device, dtype=wi_tensor.dtype).repeat(wi_tensor.shape[0], 1),  \n",
    "        torch.stack([torch.zeros_like(wi_tensor[:, 2]), 0.5 / wi_tensor[:, 2]], dim=-1) \n",
    "    ], dim=1)  \n",
    "\n",
    "    \n",
    "    jacobian_mat = torch.matmul(rot_mat, scale_mat)\n",
    "    jj_mat = torch.matmul(jacobian_mat, jacobian_mat.transpose(1, 2))\n",
    "    \n",
    "    return jj_mat\n",
    "\n",
    "\n",
    "def isotropic_ndf_filtering(si):\n",
    "    SIGMA2 = 0.15915494 # Variance of pixel filter kernel (1/(2pi))\n",
    "    KAPPA = 0.18 \n",
    "    \n",
    "    dndu = si.dn_du\n",
    "    dndv = si.dn_dv\n",
    "    roughness = si.bsdf().roughness\n",
    "\n",
    "    kernel_roughness2 = SIGMA2 * (torch.dot(dndu, dndu) + torch.dot(dndv, dndv)) # Eq. 14 in the paper\n",
    "    clamped_kernel_roughness2 = torch.clamp(kernel_roughness2, max=KAPPA)\n",
    "    filtered_roughness2 = torch.clamp(roughness**2 + clamped_kernel_roughness2, min=0.0, max=1.0)\n",
    "\n",
    "    return torch.sqrt(filtered_roughness2)\n",
    "\n",
    "def compute_filtered_roughness_mat(filtered_proj_roughness_mat, tr, det):\n",
    "    FLT_MAX = torch.finfo(torch.float32).max \n",
    "    \n",
    "    denom = 1.0 + tr + det\n",
    "    is_finite = torch.isfinite(denom) \n",
    "    \n",
    "    mat1 = (filtered_proj_roughness_mat + torch.tensor([[det, 0.0], [0.0, det]], device=filtered_proj_roughness_mat.device))\n",
    "    mat1 = torch.clamp(mat1, max=FLT_MAX) / denom\n",
    "\n",
    "    mat2 = torch.tensor([\n",
    "        [torch.clamp(filtered_proj_roughness_mat[0, 0], max=FLT_MAX) / torch.clamp(filtered_proj_roughness_mat[0, 0] + 1.0, max=FLT_MAX), 0.0],\n",
    "        [0.0, torch.clamp(filtered_proj_roughness_mat[1, 1], max=FLT_MAX) / torch.clamp(filtered_proj_roughness_mat[1, 1] + 1.0, max=FLT_MAX)]\n",
    "    ], device=filtered_proj_roughness_mat.device)\n",
    "\n",
    "    return torch.where(is_finite, mat1, mat2)\n",
    "\n",
    "# (exp(x) - 1)/x with cancellation of rounding errors.\n",
    "# [Nicholas J. Higham \"Accuracy and Stability of Numerical Algorithms\", Section 1.14.1, p. 19]\n",
    "def expm1_over_x(x):\n",
    "    u = math.exp(x)\n",
    "    if (u == 1.0):\n",
    "        return 1.0\n",
    "    y = u - 1.0\n",
    "    if (math.abs(x) < 1.0):\n",
    "        return y / math.log(u)\n",
    "    \n",
    "    return y / x\n",
    "          \n",
    "def sg_integral(sharpness):\n",
    "    return 4.0 * torch.pi * expm1_over_x(-2.0 * sharpness)\n",
    "\n",
    "def orthonormal_basis(axis: torch.Tensor):\n",
    "    s = torch.where(axis[:, 2] >= 0.0, 1.0, -1.0)  \n",
    "    c = -1.0 / (s + axis[:, 2])  \n",
    "    b = axis[:, 0] * axis[:, 1] * c  \n",
    "    b1 = torch.stack([\n",
    "        1.0 + s * axis[:, 0] * axis[:, 0] * c,\n",
    "        s * b,\n",
    "        -s * axis[:, 0]\n",
    "    ], dim=1)  \n",
    "    b2 = torch.stack([\n",
    "        b,\n",
    "        s + axis[:, 1] * axis[:, 1] * c,\n",
    "        -axis[:, 1]\n",
    "    ], dim=1)  \n",
    "\n",
    "    return torch.stack([b1, b2, axis], dim=1) \n",
    "\n",
    "def sample_vmf(axis: torch.Tensor, sharpness: torch.Tensor):\n",
    "    rand = torch.rand((axis.shape[0], 2), dtype=axis.dtype, device=axis.device) \n",
    "    phi = 2.0 * math.pi * rand[:, 0] \n",
    "    THRESHOLD = torch.finfo(torch.float32).eps / 4.0\n",
    "\n",
    "    mask = sharpness.squeeze(-1) > THRESHOLD \n",
    "    r = torch.empty_like(sharpness.squeeze(-1))\n",
    "\n",
    "    r[mask] = torch.log1p(rand[mask, 1] * torch.expm1(-2.0 * sharpness[mask, 0])) / sharpness[mask, 0]\n",
    "    r[~mask] = -2.0 * rand[~mask, 1]\n",
    "\n",
    "    cos_theta = 1.0 + r \n",
    "    sin_theta = torch.sqrt(-r * r - 2.0 * r) \n",
    "\n",
    "    dir = torch.stack([\n",
    "        torch.cos(phi) * sin_theta,  \n",
    "        torch.sin(phi) * sin_theta,  \n",
    "        cos_theta                    \n",
    "    ], dim=1) \n",
    "\n",
    "    frame = orthonormal_basis(axis)\n",
    "\n",
    "    return torch.einsum('nij,nj->ni', frame, dir) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class vapl_mixture:\n",
    "    def __init__(self, gaussians : torch.Tensor, vmfs : torch.Tensor):\n",
    "        self.mean      : torch.Tensor = gaussians[:, :3]\n",
    "        self.variance  : torch.Tensor = gaussians[:, 3]\n",
    "        self.sharpness : torch.Tensor = vmfs[:, 0]\n",
    "        self.axis      : torch.Tensor = vmfs[:, 1:4]\n",
    "        self.amplitude : torch.Tensor = vmfs[:, 4:7]\n",
    "\n",
    "        self.normalized_vapl_weights = torch.ones(gaussians.shape[0])\n",
    "        self.num_rays = gaussians.shape[0]\n",
    "    \n",
    "    def calculate_normalized_vapl_weights(self, si : mi.SurfaceInteraction3f):\n",
    "        weights = self.convolve_with_bsdf(si) \n",
    "        total_weight = torch.sum(weights) \n",
    "        self.normalized_vapl_weights = weights / total_weight  \n",
    "    \n",
    "    def sample_vapl(self, si : mi.SurfaceInteraction3f):\n",
    "        self.calculate_normalized_vapl_weights(si)\n",
    "        indices = torch.multinomial(self.normalized_vapl_weights, num_samples=self.num_rays, replacement=True)\n",
    "        \n",
    "        self.mean       = self.mean[indices]\n",
    "        self.variance   = self.variance[indices]\n",
    "        self.sharpness  = self.sharpness[indices]\n",
    "        self.axis       = self.axis[indices]\n",
    "        self.amplitude  = self.amplitude[indices]\n",
    "        self.light_lobe = self.light_lobe[indices]\n",
    "        return self\n",
    "\n",
    "\n",
    "    def convolve_with_bsdf(self, si : mi.SurfaceInteraction3f):\n",
    "        with torch.no_grad():\n",
    "            SGLIGHT_SHARPNESS_MAX = float.fromhex(\"0x1.0p41\")\n",
    "            \n",
    "            position  = si.p\n",
    "            normal    = si.n\n",
    "            tangent   = si.dp_du\n",
    "            bitangent = si.dp_dv\n",
    "\n",
    "            pos_tensor  = torch.from_numpy(position.numpy()).to(\"cuda\").T\n",
    "            norm_tensor = torch.from_numpy(normal.numpy()).to(\"cuda\").T\n",
    "\n",
    "            tangent_frame = mi.Frame3f(tangent, bitangent, normal)\n",
    "            light_vec = self.mean - pos_tensor\n",
    "            squared_distance = torch.sum(light_vec * light_vec, dim=1).unsqueeze(1)\n",
    "            light_dir = light_vec * torch.rsqrt(squared_distance)\n",
    "\n",
    "            # clamp variance for the numerical stability\n",
    "            self.variance = self.variance.unsqueeze(1)\n",
    "            variance = torch.max(self.variance, squared_distance / SGLIGHT_SHARPNESS_MAX)\n",
    "\n",
    "            # compute the maximum emissive radiance of the vapl.\n",
    "            emissive = self.amplitude / variance\n",
    "\n",
    "            # compute vapl sharpness for a light distribution viewed from the shading point.\n",
    "            light_sharpness = squared_distance / variance\n",
    "            self.sharpness = self.sharpness.unsqueeze(1)\n",
    "            # light lobe given by the product of the light distribution viewed \n",
    "            # from the shading point and the directional distribution of the vapl.\n",
    "            light_lobe_axis, light_lobe_sharpness, light_lobe_log_amplitude = sg_product(\n",
    "                self.axis, self.sharpness, light_dir, light_sharpness)\n",
    "\n",
    "            self.light_lobe = torch.cat([light_lobe_axis, light_lobe_sharpness, light_lobe_log_amplitude], dim=1)\n",
    "            # bsdf at the current intersection\n",
    "            bsdf: mi.cuda_ad_rgb.BSDFPtr = si.bsdf()\n",
    "\n",
    "            # Create BSDF contexts\n",
    "            ctx_diffuse = mi.BSDFContext()\n",
    "            ctx_diffuse.type_mask = mi.BSDFFlags.Diffuse\n",
    "\n",
    "            ctx_specular = mi.BSDFContext()\n",
    "            ctx_specular.type_mask = mi.BSDFFlags.Glossy\n",
    "\n",
    "            # Local outgoing direction\n",
    "            wo = si.to_local(-si.wi)\n",
    "    \n",
    "            # TODO: figure out how to calculate diffuse and specular corret\n",
    "            diffuse = bsdf.eval_diffuse_reflectance(si)\n",
    "            diffuse_test = bsdf.eval(ctx_diffuse, si, wo)\n",
    "            specular = bsdf.eval(ctx_specular, si, wo)\n",
    "\n",
    "            # Diffuse SG lighting.\n",
    "\t\t    # [Tokuyoshi et al. 2024 \"Hierarchical Light Sampling with Accurate Spherical Gaussian Lighting\", Section 4]\n",
    "            amplitude = torch.exp(light_lobe_log_amplitude)\n",
    "            cosine = torch.clamp(torch.sum(light_lobe_axis * norm_tensor, dim=1), -1.0, 1.0).unsqueeze(1)\n",
    "\n",
    "            diffuse_illumination = amplitude * sg_clamp_cosine_product_integral_over_pi(cosine, light_lobe_sharpness)\n",
    "\n",
    "            diffuse_tensor = torch.stack([\n",
    "                torch.from_numpy(diffuse.x.numpy()).to(\"cuda\"),\n",
    "                torch.from_numpy(diffuse.y.numpy()).to(\"cuda\"),\n",
    "                torch.from_numpy(diffuse.z.numpy()).to(\"cuda\")\n",
    "            ], dim=1)\n",
    "\n",
    "            result = emissive * diffuse_tensor * diffuse_illumination\n",
    "\n",
    "            # Store diffuse part of light to calculate Loss later\n",
    "            self.diffuse_illumination = result\n",
    "\n",
    "            return luminance(result)\n",
    "\n",
    "            # Compute JJ^T for NDF filtering.\n",
    "            wi = si.wi\n",
    "            jj_mat = compute_jacobian(wi)\n",
    "\n",
    "            # Compute determinant of JJ^T \n",
    "            det_jj4 = 1.0 / (4.0 * wi.z * wi.z)\n",
    "\n",
    "            roughness = isotropic_ndf_filtering(si)\n",
    "            roughness2 = roughness**2\n",
    "            proj_roughness2 = roughness2 / max(1.0 - roughness2, sys.float_info.min)\n",
    "            roughness_max2 = max(roughness2[0], roughness2[1])\n",
    "            reflect_sharpness = (1.0 - roughness_max2) / max(2.0 * roughness_max2, sys.float_info.min)\n",
    "            reflect_vec = mi.reflect(si.wi, normal) * reflect_sharpness\n",
    "\n",
    "            print(\"convolve bsdf glossy SG Light\")\n",
    "            # Glossy SG lighting.\n",
    "\t\t    # [Tokuyoshi et al. 2024 \"Hierarchical Light Sampling with Accurate Spherical Gaussian Lighting\", Section 5]\n",
    "            prod_vec = reflect_vec + light_lobe.axis * light_lobe.sharpness\n",
    "            prod_sharpness = torch.linalg.norm(prod_vec)\n",
    "            prod_dir = prod_vec / prod_sharpness\n",
    "            light_lobe_variance = 1.0 / light_lobe.sharpness\n",
    "            filtered_proj_roughness_mat = torch.tensor([\n",
    "                [proj_roughness2[0], 0.0],\n",
    "                [0.0, proj_roughness2[1]]], \n",
    "                device=proj_roughness2.device) + 2.0 * light_lobe_variance * jj_mat\n",
    "\n",
    "            # Compute the determinant of filteredProjRoughnessMat in a numerically stable manner.\n",
    "\t\t    # See the supplementary document (Section 5.2) of the paper for the derivation.\n",
    "            det = proj_roughness2[0] * proj_roughness2[1] + 2.0 * light_lobe_variance * (proj_roughness2[0] * jj_mat[0, 0] + proj_roughness2[1] * jj_mat[1, 1]) + light_lobe_variance * light_lobe_variance * det_jj4\n",
    "\n",
    "            # NDF filtering in a numerically stable manner\n",
    "            # See the supplementary document (Section 5.2) of the paper for the derivation\n",
    "            tr = filtered_proj_roughness_mat[0, 0] + filtered_proj_roughness_mat[1, 1]\n",
    "            filtered_roughness_mat = compute_filtered_roughness_mat(filtered_proj_roughness_mat, tr, det)\n",
    "            lobe = sgg_reflection_pdf(wi, half_vec, filtered_roughness_mat)\n",
    "\n",
    "            # visibility of the SG light in the upper hemisphere.\n",
    "            visibility = vmf_hemispherical_integral(torch.dot(prod_dir, normal), prod_sharpness)\n",
    "\n",
    "            # evaluate the filtered reflection lobe\n",
    "            light_lobe.axis = tangent_frame.to_local(light_lobe.axis)\n",
    "            print(light_lobe.axis)\n",
    "            half_vec_unnormalize = wi + tangent_frame.to_local(light_lobe.axis)\n",
    "            half_vec = half_vec_unnormalize / torch.maximum(torch.norm(half_vec_unnormalize), torch.tensor(torch.finfo(torch.float32).eps))\n",
    "\n",
    "            specular_illumination = amplitude * visibility * lobe * sg_integral(light_lobe.sharpness)\n",
    "\n",
    "            # Is that correct convolution?\n",
    "            result = emissive * (diffuse * diffuse_illumination + specular * specular_illumination)\n",
    "            return luminance(result)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is possible to just use render_rhs and RHSIntegrator from \n",
    "# https://github.com/krafton-ai/neural-radiosity-tutorial-mitsuba3/blob/main/neural_radiosity.ipynb\n",
    "\n",
    "@dr.syntax\n",
    "def first_non_specular_or_null_si(scene, si, sampler):\n",
    "    \"\"\"Find the first non-specular or null surface interaction.\"\"\"\n",
    "    with dr.suspend_grad():\n",
    "        bsdf_ctx = mi.BSDFContext()\n",
    "        depth = mi.UInt32(0)\n",
    "        β = mi.Spectrum(1)\n",
    "        bsdf = si.bsdf()\n",
    "        \n",
    "        null_face = ~mi.has_flag(si.bsdf().flags(), mi.BSDFFlags.BackSide) & (si.wi.z < 0)\n",
    "        active = si.is_valid() & ~null_face  # non-null surface\n",
    "        active &= ~mi.has_flag(si.bsdf().flags(), mi.BSDFFlags.Smooth)  # Delta surface\n",
    "\n",
    "        max_depth = 6\n",
    "        \n",
    "        while active & (depth < max_depth):\n",
    "            bsdf_sample, bsdf_weight = bsdf.sample(\n",
    "                bsdf_ctx, si, sampler.next_1d(), sampler.next_2d(), active\n",
    "            )\n",
    "            ray = si.spawn_ray(si.to_world(bsdf_sample.wo))\n",
    "            si = scene.ray_intersect(\n",
    "                ray, ray_flags=mi.RayFlags.All, coherent=depth == 0\n",
    "            )\n",
    "            bsdf = si.bsdf(ray)\n",
    "            \n",
    "            β *= bsdf_weight\n",
    "            depth[si.is_valid()] += 1\n",
    "\n",
    "            null_face &= ~mi.has_flag(bsdf.flags(), mi.BSDFFlags.BackSide) & (si.wi.z < 0)\n",
    "            active &= si.is_valid() & ~null_face\n",
    "            active &= ~mi.has_flag(bsdf.flags(), mi.BSDFFlags.Smooth)\n",
    "\n",
    "    return si, β, null_face\n",
    "\n",
    "\n",
    "def render_rhs(scene : mi.Scene, model, si : mi.SurfaceInteraction3f, sampler):\n",
    "    with dr.suspend_grad():\n",
    "        # get the vapl mixture for this intersection\n",
    "        gaussians, vmfs = model(si)\n",
    "        mixture = vapl_mixture(gaussians, vmfs)\n",
    "        sampled_vapls = mixture.sample_vapl(si)\n",
    "\n",
    "        # Calculating new sample direction\n",
    "        # 1st option - Sample direction from sampled vapl light lobe\n",
    "        light_lobe = sampled_vapls.light_lobe\n",
    "        light_lobe_axis, light_lobe_sharpness, light_lobe_log_amplitude = torch.split(light_lobe, [3, 1, 1], dim=1)\n",
    "        sampled_dir : torch.Tensor = sample_vmf(light_lobe_axis, light_lobe_sharpness)\n",
    "\n",
    "        # 2nd option - Sample direction according to BSDF x vapl convolution\n",
    "        # TODO: sample Diffuse/Specular BSDF and calculate it\n",
    "        # Specular BSDF - Anisotropic Spherical Gaussian\n",
    "        # Diffuse BSDF  - Cosine Lobe\n",
    "\n",
    "        # All the stuff from original render_rhs function\n",
    "        bsdf_ctx = mi.BSDFContext()\n",
    "        depth = mi.UInt32(0)\n",
    "        L = mi.Spectrum(0)\n",
    "        β = mi.Spectrum(1)\n",
    "        η = mi.Float(1)\n",
    "        prev_si = dr.zeros(mi.SurfaceInteraction3f)\n",
    "        prev_bsdf_pdf = mi.Float(1.0)\n",
    "        prev_bsdf_delta = mi.Bool(True)\n",
    "        bsdf = si.bsdf()\n",
    "        Le = β * si.emitter(scene).eval(si)\n",
    "        \n",
    "        # emitter sampling\n",
    "        active_next = si.is_valid()\n",
    "        active_em = active_next & mi.has_flag(bsdf.flags(), mi.BSDFFlags.Smooth)\n",
    "        ds, em_weight = scene.sample_emitter_direction(\n",
    "            si, sampler.next_2d(), True, active_em\n",
    "        )\n",
    "        active_em &= (ds.pdf != 0.0)\n",
    "        wo = si.to_local(ds.d)\n",
    "        bsdf_value_em, bsdf_pdf_em = bsdf.eval_pdf(bsdf_ctx, si, wo, active_em)\n",
    "        mis_em = dr.select(ds.delta, 1, mis_weight(ds.pdf, bsdf_pdf_em))\n",
    "        Lr_dir = β * mis_em * bsdf_value_em * em_weight\n",
    "        # update\n",
    "        L = L + Le + Lr_dir\n",
    "\n",
    "        permute_sampled_dir = sampled_dir.permute(1, 0)\n",
    "        new_dir = mi.cuda_ad_rgb.Vector3f(permute_sampled_dir)\n",
    "        ray = si.spawn_ray(si.to_world(new_dir))\n",
    "\n",
    "        η = η\n",
    "        # TODO: maybe need to get weight\n",
    "        #β *= weight\n",
    "        \n",
    "        prev_si = dr.detach(si, True)\n",
    "        #prev_bsdf_pdf = bsdf_sample.pdf\n",
    "        #prev_bsdf_delta = mi.has_flag(bsdf_sample.sampled_type, mi.BSDFFlags.Delta)\n",
    "        si = scene.ray_intersect(ray, ray_flags=mi.RayFlags.All, coherent=True)\n",
    "        ds = mi.DirectionSample3f(scene, si=si, ref=prev_si)\n",
    "        # mis = mis_weight(\n",
    "        #     prev_bsdf_pdf,\n",
    "        #     scene.pdf_emitter_direction(prev_si, ds, ~prev_bsdf_delta),\n",
    "        # )\n",
    "\n",
    "        si, β2, null_face = first_non_specular_or_null_si(scene, si, sampler)\n",
    "        β *= β2\n",
    "        mis = 1\n",
    "        L += β * mis * si.emitter(scene).eval(si) # Li (x1, wo)\n",
    "\n",
    "        # Light calculation based on model that we don't need\n",
    "        out = model(si)\n",
    "        active_nr = (\n",
    "            si.is_valid()\n",
    "            & ~null_face\n",
    "            & si.emitter(scene).eval(si) == mi.Spectrum(0)\n",
    "        )\n",
    "        Le = L\n",
    "        w_nr = β * mis\n",
    "        L = Le + dr.select(active_nr, w_nr * mi.Spectrum(out), 0)\n",
    "\n",
    "        # Calculate grads\n",
    "        gaussians.requires_grad_(True)\n",
    "        vmfs.requires_grad_(True)\n",
    "\n",
    "        # Minimize error\n",
    "        # with torch.no_grad():\n",
    "        #     pass\n",
    "\n",
    "        return L, Le, out, w_nr, active_nr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RHSIntegrator(ADIntegrator):\n",
    "    def __init__(self, props, model):\n",
    "        super().__init__(props)\n",
    "        self.model = model\n",
    "\n",
    "    def sample(self,\n",
    "               mode: dr.ADMode,\n",
    "               scene: mi.Scene,\n",
    "               sampler: mi.Sampler,\n",
    "               ray: mi.Ray3f,\n",
    "               depth: mi.UInt32,\n",
    "               δL,\n",
    "               δaovs,\n",
    "               state_in,\n",
    "               active):\n",
    "        w, h = list(scene.sensors()[0].film().size())\n",
    "        L = mi.Spectrum(0)\n",
    "\n",
    "        ray = mi.Ray3f(dr.detach(ray))\n",
    "        si = scene.ray_intersect(\n",
    "            ray, ray_flags=mi.RayFlags.All, coherent=(depth == 0)\n",
    "        )\n",
    "        # update si and bsdf with the first non-specular ones\n",
    "        si, β, _ = first_non_specular_or_null_si(scene, si, sampler)\n",
    "        L, _, _, _, _ = render_rhs(scene, self.model, si, sampler)\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        return β * L, si.is_valid(), None\n",
    "\n",
    "# test that vapl grid and mixture works\n",
    "field = vapl_grid(scene.bbox().min, scene.bbox().max, 1, 4, 8).cuda()\n",
    "\n",
    "rhs_integrator = RHSIntegrator(mi.Properties(), field)\n",
    "rhs_image = mi.render(scene=scene, spp=1, integrator=rhs_integrator)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.patch.set_visible(False)  # Hide the figure's background\n",
    "ax.axis('off')  # Remove the axes from the image\n",
    "fig.tight_layout()  # Remove any extra white spaces around the image\n",
    "ax.imshow(np.clip(rhs_image ** (1.0 / 2.2), 0, 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
